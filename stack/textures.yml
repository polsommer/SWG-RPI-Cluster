vversion: "4.0"

networks:
  cluster_net:
    external: true

volumes:
  textures-share:
    driver: local
    driver_opts:
      type: nfs
      o: addr=pi-manager,rw,nfsvers=4
      device: ":/srv/textures"
  redis-data:

configs:
  metadata-analyzer-script:
    file: ./metadata_analyzer.py

services:

  # ---------------------------------------------------------
  # Redis bus (central queue)
  # ---------------------------------------------------------
  redis-bus:
    image: redis:7-alpine
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
    networks:
      - cluster_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 30s

  # ---------------------------------------------------------
  # Texture ingestion (watches incoming directory and publishes to Redis)
  # ---------------------------------------------------------
  texture-ingestion:
    image: python:3.11-slim
    command:
      - /bin/sh
      - -c
      - |
        pip install --no-cache-dir redis watchdog && \
        python - <<'PY'
        import hashlib
        import json
        import os
        from datetime import datetime
        from pathlib import Path
        from threading import Event

        from redis import Redis
        from watchdog.events import FileSystemEventHandler
        from watchdog.observers import Observer


        def file_hash(path: Path) -> str:
            digest = hashlib.sha256()
            with path.open("rb") as file_handle:
                for chunk in iter(lambda: file_handle.read(8192), b""):
                    digest.update(chunk)
            return digest.hexdigest()


        def publish(redis_client: Redis, channel: str, message: dict, task_list: str | None, task_stream: str | None) -> None:
            payload = json.dumps(message, separators=(",", ":"))
            redis_client.publish(channel, payload)
            if task_list:
                redis_client.rpush(task_list, payload)
            if task_stream:
                redis_client.xadd(task_stream, {"event": payload})


        def build_message(path: Path) -> dict:
            stat = path.stat()
            return {
                "event": "file_detected",
                "path": str(path),
                "hash": file_hash(path),
                "size": stat.st_size,
                "mtime": datetime.utcfromtimestamp(stat.st_mtime).isoformat() + "Z",
                "timestamp": datetime.utcnow().isoformat() + "Z",
            }


        class TextureIngestHandler(FileSystemEventHandler):
            def __init__(self, seen: set[str], publisher):
                super().__init__()
                self.seen = seen
                self.publisher = publisher

            def _handle_path(self, path: Path) -> None:
                if not path.exists() or path.is_dir():
                    return
                resolved = str(path.resolve())
                if resolved in self.seen:
                    return
                self.seen.add(resolved)
                message = build_message(path)
                self.publisher(message)

            def on_created(self, event):
                if event.is_directory:
                    return
                self._handle_path(Path(event.src_path))

            def on_moved(self, event):
                if event.is_directory:
                    return
                self._handle_path(Path(event.dest_path))


        def prime_cache(directory: Path, handler: TextureIngestHandler) -> None:
            for path in directory.rglob("*"):
                if path.is_file():
                    handler._handle_path(path)


        def main() -> None:
            redis_url = os.environ.get("REDIS_URL", "redis://redis-bus:6379/0")
            channel = os.environ.get("INGEST_CHANNEL", "texture:ingest")
            path = Path(os.environ.get("TEXTURE_PATH", "/srv/textures/incoming"))
            task_list = os.environ.get("INGEST_TASK_LIST")
            task_stream = os.environ.get("INGEST_TASK_STREAM")

            redis_client = Redis.from_url(redis_url)
            path.mkdir(parents=True, exist_ok=True)

            seen: set[str] = set()
            publisher = lambda message: publish(redis_client, channel, message, task_list, task_stream)
            handler = TextureIngestHandler(seen, publisher)

            prime_cache(path, handler)

            observer = Observer()
            observer.schedule(handler, str(path), recursive=True)
            observer.start()

            stop_event = Event()
            try:
                stop_event.wait()
            except KeyboardInterrupt:
                pass
            finally:
                observer.stop()
                observer.join()


        if __name__ == "__main__":
            main()
        PY
    environment:
      REDIS_URL: redis://redis-bus:6379/0
      INGEST_CHANNEL: texture:ingest
      TEXTURE_PATH: /srv/textures/incoming
      OUTPUT_PATH: /srv/textures/processed
    volumes:
      - textures-share:/srv/textures
    networks:
      - cluster_net
    depends_on:
      - redis-bus
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import os; from redis import Redis; Redis.from_url(os.environ.get('REDIS_URL','redis://redis-bus:6379/0')).ping()",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.role == worker
          - node.labels.gpu != true
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 60s
      update_config:
        parallelism: 1
        order: start-first

  # ---------------------------------------------------------
  # ESRGAN GPU upscaler
  # ---------------------------------------------------------
  esrgan-upscaler-gpu:
    image: ghcr.io/swg-rpi-cluster/esrgan-upscaler-gpu:latest
    command:
      - /bin/sh
      - -c
      - |
        python3 - <<'PY'
        import json
        import os
        import pathlib
        import subprocess
        import time
        import urllib.request

        from redis import Redis

        redis = Redis.from_url(os.environ.get("REDIS_URL", "redis://redis-bus:6379/0"), decode_responses=True)

        input_channel = os.environ.get("INPUT_CHANNEL", "texture:ingest")
        output_channel = os.environ.get("OUTPUT_CHANNEL", "texture:upscaled")
        texture_root = pathlib.Path(os.environ.get("TEXTURE_PATH", "/srv/textures")).resolve()
        output_root = pathlib.Path(os.environ.get("OUTPUT_PATH", texture_root / "output")).resolve()
        model = os.environ.get("MODEL", "RealESRGAN_x4plus")
        outscale = os.environ.get("OUTSCALE", "4")
        suffix = os.environ.get("OUTPUT_SUFFIX", "upscaled")
        extensions = {".png", ".jpg", ".jpeg", ".tga", ".bmp", ".dds"}

        output_root.mkdir(parents=True, exist_ok=True)

        def publish(payload):
          redis.publish(output_channel, json.dumps(payload))

        def list_targets(message: str):
          if message.startswith(("http://", "https://")):
            incoming_dir = texture_root / "incoming"
            incoming_dir.mkdir(parents=True, exist_ok=True)
            filename = incoming_dir / pathlib.Path(message.split("?")[0]).name
            try:
              urllib.request.urlretrieve(message, filename)
              return [filename]
            except Exception:
              return []

          parts = message.split()
          target = " ".join(parts[1:]) if parts[:1] == ["scan"] else message
          if not target:
            return []
          path = pathlib.Path(target).expanduser()
          try:
            path.resolve().relative_to(texture_root)
          except Exception:
            return []
          if path.is_dir():
            return [p for p in path.rglob("*") if p.suffix.lower() in extensions and p.is_file()]
          if path.is_file() and path.suffix.lower() in extensions:
            return [path]
          return []

        def expected_output(input_path: pathlib.Path):
          rel = input_path.resolve().relative_to(texture_root)
          dest_dir = (output_root / rel.parent).resolve()
          dest_dir.mkdir(parents=True, exist_ok=True)
          return dest_dir / f"{input_path.stem}_{suffix}{input_path.suffix}"

        def run_inference(src: pathlib.Path, dest: pathlib.Path):
          cmd = [
            "python3",
            "inference_realesrgan.py",
            "-n",
            model,
            "-i",
            str(src),
            "-o",
            str(dest),
            "--outscale",
            str(outscale),
            "--suffix",
            suffix,
          ]
          subprocess.run(cmd, check=True)

        publish({"status": "online", "model": model, "scale": outscale, "output_root": str(output_root)})
        pubsub = redis.pubsub()
        pubsub.subscribe(input_channel)

        for msg in pubsub.listen():
          if msg.get("type") != "message":
            continue
          body = msg.get("data") or ""
          targets = list_targets(body)
          if not targets:
            publish({"status": "ignored", "reason": "no-targets", "message": body})
            continue
          for src in targets:
            dest = expected_output(src)
            if dest.exists() and dest.stat().st_mtime >= src.stat().st_mtime:
              publish({"status": "skipped", "input": str(src), "output": str(dest), "reason": "up-to-date"})
              continue
            started = time.time()
            try:
              run_inference(src, dest)
              publish({
                "status": "completed",
                "input": str(src),
                "output": str(dest),
                "model": model,
                "scale": outscale,
                "duration_sec": round(time.time() - started, 2),
              })
            except Exception as exc:  # noqa: BLE001
              publish({"status": "error", "input": str(src), "error": str(exc)})
        PY
    environment:
      REDIS_URL: redis://redis-bus:6379/0
      INPUT_CHANNEL: texture:ingest
      OUTPUT_CHANNEL: texture:upscaled
      TEXTURE_PATH: /srv/textures
      OUTPUT_PATH: /srv/textures/output
      MODEL: RealESRGAN_x4plus
      OUTSCALE: "4"
      OUTPUT_SUFFIX: upscaled
    volumes:
      - textures-share:/srv/textures
    networks:
      - cluster_net
    healthcheck:
      test:
        [
          "CMD",
          "python3",
          "-c",
          "import os; from redis import Redis; Redis.from_url(os.environ.get('REDIS_URL','redis://redis-bus:6379/0')).ping()",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      replicas: ${ESRGAN_GPU_REPLICAS:-0}
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.role == worker
          - node.labels.gpu == true
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
      update_config:
        parallelism: 1
        order: start-first
    depends_on:
      - redis-bus

  # ---------------------------------------------------------
  # ESRGAN CPU fallback upscaler
  # ---------------------------------------------------------
  esrgan-upscaler-cpu:
    image: ghcr.io/swg-rpi-cluster/esrgan-upscaler-cpu:latest
    command:
      - /bin/sh
      - -c
      - |
        python3 - <<'PY'
        import json
        import os
        import time
        from pathlib import Path

        from redis import Redis
        from PIL import Image


        def get_env(key: str, default: str) -> str:
            return os.environ.get(key, default)


        redis = Redis.from_url(get_env("REDIS_URL", "redis://redis-bus:6379/0"), decode_responses=True)
        input_channel = get_env("INPUT_CHANNEL", "texture:ingest")
        output_channel = get_env("OUTPUT_CHANNEL", "texture:upscaled")
        base_path = Path(get_env("TEXTURE_PATH", "/srv/textures"))
        input_path = base_path / get_env("INPUT_PATH", "incoming")
        output_path = base_path / get_env("OUTPUT_PATH", "output")
        scale_factor = float(get_env("UPSCALE_FACTOR", "2"))
        max_retries = int(get_env("UPSCALE_RETRIES", "3"))
        supported_extensions = {".png", ".jpg", ".jpeg", ".bmp", ".tga", ".tif", ".tiff"}

        input_path.mkdir(parents=True, exist_ok=True)
        output_path.mkdir(parents=True, exist_ok=True)


        def publish(event: str, **payload):
            message = {"event": event, **payload}
            redis.publish(output_channel, json.dumps(message))


        def upscale_image(source: Path, destination: Path) -> bool:
            for attempt in range(1, max_retries + 1):
                try:
                    with Image.open(source) as img:
                        new_size = (int(img.width * scale_factor), int(img.height * scale_factor))
                        upscaled = img.resize(new_size, Image.LANCZOS)
                        destination.parent.mkdir(parents=True, exist_ok=True)
                        upscaled.save(destination)
                    publish(
                        "upscaled",
                        input=str(source),
                        output=str(destination),
                        scale=scale_factor,
                    )
                    return True
                except Exception as exc:  # noqa: BLE001
                    publish(
                        "error",
                        input=str(source),
                        attempt=attempt,
                        error=str(exc),
                    )
                    time.sleep(min(10, attempt * 2))
            return False


        def candidate_files(target: Path):
            if target.is_file():
                yield target
                return
            if not target.exists():
                publish("warning", message=f"Path not found: {target}")
                return
            for root, _, files in os.walk(target):
                for name in files:
                    path = Path(root) / name
                    if path.suffix.lower() in supported_extensions:
                        yield path


        def output_for(source: Path) -> Path:
            try:
                relative = source.relative_to(input_path)
            except ValueError:
                relative = source.name
            return output_path / relative


        def process_scan(scan_target: str):
            target = Path(scan_target) if scan_target else input_path
            processed = 0
            for candidate in candidate_files(target):
                destination = output_for(candidate)
                if destination.exists():
                    continue
                success = upscale_image(candidate, destination)
                processed += 1 if success else 0
            publish("scan-complete", target=str(target), processed=processed)


        def listen_and_process():
            publish(
                "cpu-upscaler-online",
                input_channel=input_channel,
                output_channel=output_channel,
                input_path=str(input_path),
                output_path=str(output_path),
            )
            pubsub = redis.pubsub(ignore_subscribe_messages=True)
            pubsub.subscribe(input_channel)
            for message in pubsub.listen():
                try:
                    payload = message.get("data")
                    if not payload:
                        continue
                    if isinstance(payload, bytes):
                        payload = payload.decode()
                    text = str(payload).strip()
                    if text.startswith("scan"):
                        parts = text.split(maxsplit=1)
                        target = parts[1] if len(parts) > 1 else str(input_path)
                        process_scan(target)
                    else:
                        process_scan(text)
                except Exception as exc:  # noqa: BLE001
                    publish("listener-error", error=str(exc))
                    time.sleep(5)


        while True:
            try:
                listen_and_process()
            except Exception as exc:  # noqa: BLE001
                publish("fatal-error", error=str(exc))
                time.sleep(5)
        PY
    environment:
      REDIS_URL: redis://redis-bus:6379/0
      INPUT_CHANNEL: texture:ingest
      OUTPUT_CHANNEL: texture:upscaled
      TEXTURE_PATH: /srv/textures
      INPUT_PATH: incoming
      OUTPUT_PATH: output
      UPSCALE_FACTOR: "2"
      UPSCALE_RETRIES: "3"
    volumes:
      - textures-share:/srv/textures
    networks:
      - cluster_net
    healthcheck:
      test:
        [
          "CMD",
          "python3",
          "-c",
          "import os; from redis import Redis; Redis.from_url(os.environ.get('REDIS_URL','redis://redis-bus:6379/0')).ping()",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    depends_on:
      - redis-bus
    deploy:
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.role == worker
          - node.labels.gpu != true
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s
      update_config:
        parallelism: 1
        order: start-first

  # ---------------------------------------------------------
  # Metadata analyzer (LLM / echo backend)
  # ---------------------------------------------------------
  metadata-analyzer:
    image: ghcr.io/swg-rpi-cluster/metadata-analyzer:latest
    command:
      - /bin/sh
      - -c
      - |
        python3 /opt/metadata_analyzer.py
    environment:
      REDIS_URL: redis://redis-bus:6379/0
      INPUT_CHANNEL: texture:upscaled
      OUTPUT_CHANNEL: texture:metadata
      SHARED_PATH: /srv/textures
      LLM_BACKEND: echo
      LLM_MODEL: gpt-4o-mini
      METADATA_SUFFIX: ".metadata.json"
      HEARTBEAT_SECONDS: "30"
    volumes:
      - textures-share:/srv/textures
    configs:
      - source: metadata-analyzer-script
        target: /opt/metadata_analyzer.py
        mode: 0444
    networks:
      - cluster_net
    healthcheck:
      test:
        [
          "CMD",
          "python3",
          "-c",
          "import os, pathlib; from redis import Redis; assert pathlib.Path('/opt/metadata_analyzer.py').exists(); Redis.from_url(os.environ.get('REDIS_URL','redis://redis-bus:6379/0')).ping()",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    depends_on:
      - redis-bus
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
          - node.labels.gpu != true
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 60s
      update_config:
        parallelism: 1
        order: start-first
